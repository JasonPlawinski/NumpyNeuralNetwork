{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cPickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-45feb6095595>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cPickle'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cPickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loader and wrapper by \"mnielsen\" https://github.com/mnielsen/neural-networks-and-deep-learning\n",
    "\n",
    "def load_data():\n",
    "    '''Loading the mnist dataset from an archive'''\n",
    "    f = gzip.open('./mnist.pkl.gz', 'rb')\n",
    "    training_data, validation_data, test_data = cPickle.load(f)\n",
    "    f.close()\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def load_data_wrapper():\n",
    "    '''Reshaping the data in a tuple with on one hand the greyscale image and on the other the the label (between 0-9)'''\n",
    "    tr_d, va_d, te_d = load_data()\n",
    "    \n",
    "    #Organizing the training set\n",
    "    training_inputs = [np.reshape(x, (784, 1)) for x in tr_d[0]]\n",
    "    training_results = [vectorized_result(y) for y in tr_d[1]]\n",
    "    training_data = zip(training_inputs, training_results)\n",
    "    \n",
    "    #Organizing the validation set\n",
    "    validation_inputs = [np.reshape(x, (784, 1)) for x in va_d[0]]\n",
    "    validation_data = zip(validation_inputs, va_d[1])\n",
    "    \n",
    "    #Organizing the testing set \n",
    "    test_inputs = [np.reshape(x, (784, 1)) for x in te_d[0]]\n",
    "    test_data = zip(test_inputs, te_d[1])\n",
    "    return (training_data, validation_data, test_data)\n",
    "\n",
    "def vectorized_result(j):\n",
    "    '''Vectorizing the output with 1 at the true label and zeroes everywhere else'''\n",
    "    e = np.zeros((10, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_data_wrapper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b705562e17ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Loading data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'load_data_wrapper' is not defined"
     ]
    }
   ],
   "source": [
    "#Loading data\n",
    "training_data, validation_data, test_data = load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-3dd2443161a1>, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-3dd2443161a1>\"\u001b[1;36m, line \u001b[1;32m73\u001b[0m\n\u001b[1;33m    print \"Epoch {0}: {1} / {2}\".format(\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Network inspired by \"mnielsen\" https://github.com/mnielsen/neural-networks-and-deep-learning\n",
    "class Network(object):\n",
    "    def __init__(self, sizes,p=0.5):\n",
    "        '''For initialization, sizes is the list of sizes of the layers [input h1 h2 h3 output]\n",
    "        p is dropout rate'''\n",
    "        #Initialization \n",
    "        #picking a random seed\n",
    "        np.random.seed(0)\n",
    "        #avoiding conditionning error in adagrad\n",
    "        self.eps = np.finfo(np.float).eps\n",
    "        #storing hyper parameters as attributes\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.p = p\n",
    "        \n",
    "        self.dropOut = self.dropOut = [np.array((np.random.rand(y, 1)<self.p),np.float) for y in self.sizes[1:]]\n",
    "        \n",
    "        #Initializing weights with low variance gaussians\n",
    "        #Initializing biases with 0\n",
    "        self.biases = [np.zeros([y, 1]) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)/5.0\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "        #Initialization of the softmax layer\n",
    "        self.weightsSoftMax = np.random.randn(10, sizes[-1])/5.0\n",
    "        self.biasSoftMax = np.zeros([10,1])\n",
    "        \n",
    "        #Initialization of loss lists for plotting\n",
    "        self.test_lost=[]\n",
    "        self.test_accuracy=[]\n",
    "    \n",
    "    def feedforward(self, a):\n",
    "        ''''''\n",
    "        for b, w, dp in zip(self.biases, self.weights, self.dropOut):\n",
    "            a = tanh(np.dot(w, a)+b)\n",
    "        a = softmax(np.dot(self.weightsSoftMax,a)+self.biasSoftMax)\n",
    "        return a \n",
    "    \n",
    "    def feedforwardNoDrop(self, a):\n",
    "        \n",
    "        index=0\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            if index == 0:\n",
    "                a = tanh(np.dot(w, a)+b)\n",
    "            else:\n",
    "                a = tanh(np.dot(w, a)+b)*p\n",
    "        a = softmax(np.dot(self.weightsSoftMax,a)+self.biasSoftMax)\n",
    "        return a \n",
    "    \n",
    "       \n",
    "    \n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta, regularization,\n",
    "            test_data=None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "        if test_data: n_test = len(test_data)\n",
    "        n = len(training_data)\n",
    "        for j in xrange(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in xrange(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.dropOut = [np.array((np.random.rand(y, 1)<self.p),np.float) for y in self.sizes[1:]]\n",
    "                self.update_mini_batch(mini_batch, eta, regularization)\n",
    "            if test_data:\n",
    "                print \"Epoch {0}: {1} / {2}\".format(\n",
    "                    j, self.evaluate(test_data), n_test)\n",
    "            else:\n",
    "                print \"Epoch {0} complete\".format(j)\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta, regularization):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_b_SM = np.zeros_like(self.biasSoftMax)\n",
    "        nabla_w_SM = np.zeros_like(self.weightsSoftMax)\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w, delta_b_SM, delta_w_SM = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "            nabla_b_SM = nabla_b_SM + delta_b_SM\n",
    "            nabla_w_SM = nabla_w_SM + delta_w_SM\n",
    "        self.weights = [w*(1-regularization*eta/len(w))-(eta/len(mini_batch))*nw \n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "        self.weightsSoftMax = self.weightsSoftMax*(1-eta*regularization/len(w)) - (eta/len(mini_batch))*nabla_w_SM \n",
    "        self.biasSoftMax -= (eta/len(mini_batch))*nabla_b_SM\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        nabla_bSM = np.zeros_like(self.biasSoftMax)\n",
    "        nabla_wSM = np.zeros_like(self.weightsSoftMax)\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs=[]\n",
    "        index=0\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = tanh(z)*self.dropOut[index]\n",
    "            activations.append(activation)\n",
    "            index += 1\n",
    "        z = (np.dot(self.weightsSoftMax, activation)+self.biasSoftMax)\n",
    "        zs.append(z) # list to store all the z vectors, layer by layer\n",
    "        activation = tanh(z)\n",
    "        activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1],y)\n",
    "        nabla_bSM = delta\n",
    "        nabla_wSM = np.dot(delta, activations[-2].transpose())\n",
    "        delta = np.dot(self.weightsSoftMax.transpose(), delta)*tanh_prime(zs[-2]) *self.dropOut[-1]\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-3].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in xrange(2, self.num_layers):\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * tanh_prime(zs[-l-1])*self.dropOut[-l]\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-2].transpose())\n",
    "        return (nabla_b, nabla_w, nabla_bSM, nabla_wSM)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforwardNoDrop(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        self.test_accuracy.append(sum(int(x == y) for (x, y) in test_results))\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations - y)\n",
    "    \n",
    "    def cost_function(self, test_data):\n",
    "        a=[np.sum(0.5*(self.feedforward(x)-1*(range(0,10)==y))**2) for (x, y) in test_data]\n",
    "        return sum(a)\n",
    "\n",
    "#### Miscellaneous functions\n",
    "def tanh(z):\n",
    "    \"\"\"The tanh function.\"\"\"\n",
    "    a= np.copy(z)\n",
    "    a[z<=0] = 0\n",
    "    return a\n",
    "\n",
    "def tanh_prime(z):\n",
    "    \"\"\"Derivative of the tanh function.\"\"\"\n",
    "    a= np.zeros_like(z)\n",
    "    a[z>0] = 1\n",
    "    return a\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute the softmax of vector x.\"\"\"\n",
    "    exps = np.exp(x - x.max())\n",
    "    return exps / np.sum(exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d7a6fe266450>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNet4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Network' is not defined"
     ]
    }
   ],
   "source": [
    "Net4=Network([784,50,30],p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 7240 / 10000\n",
      "Epoch 1: 8269 / 10000\n",
      "Epoch 2: 8469 / 10000\n",
      "Epoch 3: 8648 / 10000\n",
      "Epoch 4: 9011 / 10000\n",
      "Epoch 5: 9120 / 10000\n",
      "Epoch 6: 9146 / 10000\n",
      "Epoch 7: 9201 / 10000\n",
      "Epoch 8: 9216 / 10000\n",
      "Epoch 9: 9231 / 10000\n",
      "Epoch 10: 9277 / 10000\n",
      "Epoch 11: 9270 / 10000\n",
      "Epoch 12: 9316 / 10000\n",
      "Epoch 13: 9279 / 10000\n",
      "Epoch 14: 9263 / 10000\n",
      "Epoch 15: 9309 / 10000\n",
      "Epoch 16: 9301 / 10000\n",
      "Epoch 17: 9336 / 10000\n",
      "Epoch 18: 9361 / 10000\n",
      "Epoch 19: 9350 / 10000\n",
      "Epoch 20: 9350 / 10000\n",
      "Epoch 21: 9335 / 10000\n",
      "Epoch 22: 9333 / 10000\n",
      "Epoch 23: 9355 / 10000\n",
      "Epoch 24: 9362 / 10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a809b51c587d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNet4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-464d1a3029ca>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, regularization, test_data)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmini_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmini_batches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropOut\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 print \"Epoch {0}: {1} / {2}\".format(\n",
      "\u001b[1;32m<ipython-input-10-464d1a3029ca>\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[1;34m(self, mini_batch, eta, regularization)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mnabla_w_SM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweightsSoftMax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m             \u001b[0mdelta_nabla_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_b_SM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_w_SM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m             \u001b[0mnabla_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdnb\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdnb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnabla_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_nabla_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m             \u001b[0mnabla_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnw\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdnw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdnw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnabla_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-464d1a3029ca>\u001b[0m in \u001b[0;36mbackprop\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtanh_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropOut\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mnabla_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m             \u001b[0mnabla_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnabla_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnabla_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnabla_bSM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnabla_wSM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Net4.SGD(training_data,20,10,0.10,0.0,test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 9339 / 10000\n",
      "Epoch 1: 9503 / 10000\n",
      "Epoch 2: 9598 / 10000\n",
      "Epoch 3: 9617 / 10000\n",
      "Epoch 4: 9617 / 10000\n",
      "Epoch 5: 9694 / 10000\n",
      "Epoch 6: 9664 / 10000\n",
      "Epoch 7: 9672 / 10000\n",
      "Epoch 8: 9703 / 10000\n",
      "Epoch 9: 9729 / 10000\n"
     ]
    }
   ],
   "source": [
    "Net2=Network([784,50,30],p=1)\n",
    "Net2.SGD(training_data,10,10,0.10,0.05,test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 9317 / 10000\n",
      "Epoch 1: 9448 / 10000\n",
      "Epoch 2: 9507 / 10000\n",
      "Epoch 3: 9545 / 10000\n",
      "Epoch 4: 9575 / 10000\n",
      "Epoch 5: 9621 / 10000\n",
      "Epoch 6: 9617 / 10000\n",
      "Epoch 7: 9604 / 10000\n",
      "Epoch 8: 9611 / 10000\n",
      "Epoch 9: 9639 / 10000\n"
     ]
    }
   ],
   "source": [
    "Net3=Network([784,50,30],p=1)\n",
    "Net3.SGD(training_data,10,10,0.15,0.0,test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Net.test_lost)\n",
    "plt.plot(Net2.test_lost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe6ac710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(Net3.test_accuracy)*(1/100.0),'o-',label='Vanilla')\n",
    "plt.plot(np.array(Net.test_accuracy)*(1/100.0),'o-',label='Dropout rate (p=0.7)')\n",
    "plt.plot(np.array(Net2.test_accuracy)*(1/100.0),'o-',label='L2 Regularization')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy % on test set')\n",
    "plt.legend()\n",
    "plt.savefig('regularization.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.079504  ],\n",
       "       [ 0.01489715],\n",
       "       [ 0.14786687],\n",
       "       [ 0.0123601 ],\n",
       "       [ 0.06376704],\n",
       "       [ 0.00883957],\n",
       "       [ 0.03666194],\n",
       "       [ 0.12975522],\n",
       "       [ 0.03382194],\n",
       "       [ 0.47252617]])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net.feedforward(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.]]), array([[ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        [ 0.]])]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net.dropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
